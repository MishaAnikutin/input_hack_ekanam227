{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d35f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snscrape in c:\\python\\lib\\site-packages (0.7.0.20230622)\n",
      "Requirement already satisfied: requests[socks] in c:\\python\\lib\\site-packages (from snscrape) (2.32.3)\n",
      "Requirement already satisfied: lxml in c:\\python\\lib\\site-packages (from snscrape) (4.9.4)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python\\lib\\site-packages (from snscrape) (4.13.3)\n",
      "Requirement already satisfied: filelock in c:\\python\\lib\\site-packages (from snscrape) (3.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python\\lib\\site-packages (from beautifulsoup4->snscrape) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\python\\lib\\site-packages (from beautifulsoup4->snscrape) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests[socks]->snscrape) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests[socks]->snscrape) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests[socks]->snscrape) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lib\\site-packages (from requests[socks]->snscrape) (2025.1.31)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\python\\lib\\site-packages (from requests[socks]->snscrape) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8427476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import snscrape\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Парсинг канала: investokrat\n",
      "Парсинг канала: tb_invest_official\n",
      "Парсинг канала: alfa_investments\n",
      "Парсинг канала: Coin_Post\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import snscrape\n",
    "import json\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "class TelegramParser:\n",
    "    def __init__(self, output_file: str = \"telegram_data.csv\"):\n",
    "        self.output_file = output_file\n",
    "        self.df = pd.DataFrame(columns=['text', 'title', 'url', 'source', 'date'])\n",
    "        self._load_existing_data()\n",
    "        \n",
    "    def _load_existing_data(self):\n",
    "        \"\"\"Загрузка существующих данных из CSV\"\"\"\n",
    "        if os.path.exists(self.output_file):\n",
    "            self.df = pd.read_csv(self.output_file)\n",
    "            self.df['date'] = pd.to_datetime(self.df['date'])\n",
    "            \n",
    "    def _parse_channel(self, channel: str, start_date: str = None) -> pd.DataFrame:\n",
    "        \"\"\"Парсинг одного канала\"\"\"\n",
    "        try:\n",
    "            # Формируем команду для snscrape\n",
    "            cmd = [\"snscrape\", \"--jsonl\", \"telegram-channel\", channel]\n",
    "            \n",
    "            if start_date:\n",
    "                cmd.extend([\"--since\", start_date])\n",
    "                \n",
    "            # Запускаем процесс и получаем вывод\n",
    "            result = subprocess.run(\n",
    "                cmd,\n",
    "                check=True,\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=300\n",
    "            )\n",
    "            \n",
    "            # Парсим результат\n",
    "            posts = []\n",
    "            for line in result.stdout.split('\\n'):\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    post = {\n",
    "                        'text': data.get('content', ''),\n",
    "                        'title': f\"{channel}_{data.get('id', '')}\",\n",
    "                        'url': data.get('url', ''),\n",
    "                        'date': data.get('date', ''),\n",
    "                        'source': f\"tg_{channel}\"\n",
    "                    }\n",
    "                    posts.append(post)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "                    \n",
    "            return pd.DataFrame(posts)\n",
    "            \n",
    "        except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:\n",
    "            print(f\"Ошибка парсинга {channel}: {str(e)}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def _update_data(self, new_data: pd.DataFrame):\n",
    "        \"\"\"Обновление основного DataFrame\"\"\"\n",
    "        if not new_data.empty:\n",
    "            # Конвертируем даты\n",
    "            new_data['date'] = pd.to_datetime(new_data['date'])\n",
    "            \n",
    "            # Объединяем данные и удаляем дубликаты\n",
    "            self.df = pd.concat([self.df, new_data], ignore_index=True)\n",
    "            self.df = self.df.drop_duplicates(subset='url', keep='first')\n",
    "            \n",
    "            # Сохраняем в файл\n",
    "            self.df.to_csv(self.output_file, index=False)\n",
    "            \n",
    "    def parse_channels(self, channels: List[str], start_date: str = None):\n",
    "        \"\"\"Парсинг списка каналов\"\"\"\n",
    "        for channel in channels:\n",
    "            print(f\"Парсинг канала: {channel}\")\n",
    "            channel_data = self._parse_channel(channel, start_date)\n",
    "            self._update_data(channel_data)\n",
    "            time.sleep(1)  # Задержка между запросами\n",
    "            \n",
    "    def start_periodic_parsing(self, channels: List[str], interval: int = 600):\n",
    "        \"\"\"Запуск периодического парсинга\"\"\"\n",
    "        while True:\n",
    "            print(f\"Начало нового цикла парсинга в {datetime.now()}\")\n",
    "            self.parse_channels(channels)\n",
    "            print(f\"Следующий цикл через {interval//60} минут...\")\n",
    "            time.sleep(interval)\n",
    "\n",
    "    def get_last_date(self) -> str:\n",
    "        \"\"\"Получение последней даты в данных\"\"\"\n",
    "        if not self.df.empty:\n",
    "            return self.df['date'].max().strftime('%Y-%m-%d')\n",
    "        return None\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    parser = TelegramParser()\n",
    "    channels = [\"investokrat\", 'tb_invest_official', 'alfa_investments', 'Coin_Post']\n",
    "    \n",
    "    # Первоначальный парсинг за последние 7 дней\n",
    "    start_date = (datetime.now() - timedelta(days=1)).strftime(\"%Y.%m.%d\")\n",
    "    parser.parse_channels(channels)\n",
    "    \n",
    "    # Запуск периодического парсинга каждые 10 минут\n",
    "    # parser.start_periodic_parsing(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e0067",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('telegram_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a90e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>investokrat_</td>\n",
       "      <td>https://t.me/s/investokrat/2634</td>\n",
       "      <td>tg_investokrat</td>\n",
       "      <td>2025-06-08 08:10:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>investokrat_</td>\n",
       "      <td>https://t.me/s/investokrat/2633</td>\n",
       "      <td>tg_investokrat</td>\n",
       "      <td>2025-06-08 08:08:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fusion Factor выкупает АДР NanduQ (QIWI) на М...</td>\n",
       "      <td>investokrat_</td>\n",
       "      <td>https://t.me/s/investokrat/2632</td>\n",
       "      <td>tg_investokrat</td>\n",
       "      <td>2025-06-06 09:01:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>💛 #BTC: Новый фьючерс от Мосбиржи на биткоинС ...</td>\n",
       "      <td>investokrat_</td>\n",
       "      <td>https://t.me/s/investokrat/2631</td>\n",
       "      <td>tg_investokrat</td>\n",
       "      <td>2025-06-06 05:05:58+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>💼 Программа долгосрочных сбережений - от А до ...</td>\n",
       "      <td>investokrat_</td>\n",
       "      <td>https://t.me/s/investokrat/2629</td>\n",
       "      <td>tg_investokrat</td>\n",
       "      <td>2025-06-05 04:10:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15270</th>\n",
       "      <td>Сегодня предлагаем присмотреться к газовому се...</td>\n",
       "      <td>alfa_investments_</td>\n",
       "      <td>https://t.me/s/alfa_investments/14</td>\n",
       "      <td>tg_alfa_investments</td>\n",
       "      <td>2021-06-29 13:17:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15271</th>\n",
       "      <td>NaN</td>\n",
       "      <td>alfa_investments_</td>\n",
       "      <td>https://t.me/s/alfa_investments/13</td>\n",
       "      <td>tg_alfa_investments</td>\n",
       "      <td>2021-06-29 07:45:51+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15272</th>\n",
       "      <td>Как быстро понять, что происходит на рынках? П...</td>\n",
       "      <td>alfa_investments_</td>\n",
       "      <td>https://t.me/s/alfa_investments/12</td>\n",
       "      <td>tg_alfa_investments</td>\n",
       "      <td>2021-06-29 07:45:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15273</th>\n",
       "      <td>Давайте знакомиться 👋Привет! Это команда Альфа...</td>\n",
       "      <td>alfa_investments_</td>\n",
       "      <td>https://t.me/s/alfa_investments/9</td>\n",
       "      <td>tg_alfa_investments</td>\n",
       "      <td>2021-06-29 05:37:41+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15274</th>\n",
       "      <td>Channel created</td>\n",
       "      <td>alfa_investments_</td>\n",
       "      <td>https://t.me/s/alfa_investments/1</td>\n",
       "      <td>tg_alfa_investments</td>\n",
       "      <td>2021-06-18 14:04:02+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15275 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text              title  \\\n",
       "0                                                    NaN       investokrat_   \n",
       "1                                                    NaN       investokrat_   \n",
       "2       Fusion Factor выкупает АДР NanduQ (QIWI) на М...       investokrat_   \n",
       "3      💛 #BTC: Новый фьючерс от Мосбиржи на биткоинС ...       investokrat_   \n",
       "4      💼 Программа долгосрочных сбережений - от А до ...       investokrat_   \n",
       "...                                                  ...                ...   \n",
       "15270  Сегодня предлагаем присмотреться к газовому се...  alfa_investments_   \n",
       "15271                                                NaN  alfa_investments_   \n",
       "15272  Как быстро понять, что происходит на рынках? П...  alfa_investments_   \n",
       "15273  Давайте знакомиться 👋Привет! Это команда Альфа...  alfa_investments_   \n",
       "15274                                    Channel created  alfa_investments_   \n",
       "\n",
       "                                      url               source  \\\n",
       "0         https://t.me/s/investokrat/2634       tg_investokrat   \n",
       "1         https://t.me/s/investokrat/2633       tg_investokrat   \n",
       "2         https://t.me/s/investokrat/2632       tg_investokrat   \n",
       "3         https://t.me/s/investokrat/2631       tg_investokrat   \n",
       "4         https://t.me/s/investokrat/2629       tg_investokrat   \n",
       "...                                   ...                  ...   \n",
       "15270  https://t.me/s/alfa_investments/14  tg_alfa_investments   \n",
       "15271  https://t.me/s/alfa_investments/13  tg_alfa_investments   \n",
       "15272  https://t.me/s/alfa_investments/12  tg_alfa_investments   \n",
       "15273   https://t.me/s/alfa_investments/9  tg_alfa_investments   \n",
       "15274   https://t.me/s/alfa_investments/1  tg_alfa_investments   \n",
       "\n",
       "                            date  \n",
       "0      2025-06-08 08:10:23+00:00  \n",
       "1      2025-06-08 08:08:29+00:00  \n",
       "2      2025-06-06 09:01:04+00:00  \n",
       "3      2025-06-06 05:05:58+00:00  \n",
       "4      2025-06-05 04:10:04+00:00  \n",
       "...                          ...  \n",
       "15270  2021-06-29 13:17:00+00:00  \n",
       "15271  2021-06-29 07:45:51+00:00  \n",
       "15272  2021-06-29 07:45:16+00:00  \n",
       "15273  2021-06-29 05:37:41+00:00  \n",
       "15274  2021-06-18 14:04:02+00:00  \n",
       "\n",
       "[15275 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a314d9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f40ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
